input { 
        kafka {
        "bootstrap_servers" => "192.168.0.237:9092"
        "topics" => ["reconia"]
    }}
    
    filter {
                ruby {
                init => "require 'json'"
                code => '
                    eventHash = event.to_hash
                    hash = JSON.parse(eventHash["message"])
                    event.set("data", [hash["prenom"],hash["nom"],hash["mail"],hash["age"]])
                '
            }
                mutate {
                    add_field => {
                    "fields" => ["first_name", "last_name", "mail", "age"]
    "comparators" => ["no.priv.garshol.duke.comparators.Levenshtein", "no.priv.garshol.duke.comparators.Levenshtein", "org.minibig.duke.miniduke.EmailComparator", "no.priv.garshol.duke.comparators.Levenshtein"]
    "data" => ["%{prenom}", "%{nom}", "%{mail}", "%{age}"]
                    "weight" => [[0.4, 0.6], [0.3, 0.8], [0.5, 0.95], [0.4, 0.6]]
                    "filters" => ["first_name", "last_name", "mail", "age"]
    "threshold" => 0.95
                    }
                    }
                    prune {
                        whitelist_names => ["fields", "comparator", "data", "weight", "filters", "timestamp"]
                    }
                    }output {
                    elasticsearch { 
                        hosts => ["localhost:9200"]
                        index => "logstash_test"
                        document_type => "mdm"
                        pipeline => "miniduke"
                    }
                  stdout { codec => rubydebug }
                }